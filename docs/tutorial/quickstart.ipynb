{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n",
    "This tutorial will guide you through the basics of using `braintaichi` to create high-performance brain dynamics operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, make sure you have installed `braintaichi`:\n",
    "\n",
    "```bash\n",
    "pip install braintaichi\n",
    "```\n",
    "\n",
    "Or install from source:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/chaoming0625/braintaichi.git\n",
    "cd braintaichi\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Let's start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:52:47.301619Z",
     "start_time": "2025-10-29T14:52:47.298517Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import taichi as ti\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import braintaichi as bti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Vector Addition\n",
    "\n",
    "Let's start with a simple example - vector addition using Taichi kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:52:16.676823Z",
     "start_time": "2025-10-29T14:52:16.672825Z"
    }
   },
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def vector_add(\n",
    "    a: ti.types.ndarray(ndim=1),\n",
    "    b: ti.types.ndarray(ndim=1),\n",
    "    out: ti.types.ndarray(ndim=1)\n",
    "):\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "# Register the custom operator\n",
    "vector_add_op = bti.XLACustomOp(\n",
    "    cpu_kernel=vector_add,\n",
    "    gpu_kernel=vector_add\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:52:22.674737Z",
     "start_time": "2025-10-29T14:52:22.415505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "Input b: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Result: [Array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Test the operator\n",
    "n = 10\n",
    "a = jnp.arange(n, dtype=jnp.float32)\n",
    "b = jnp.ones(n, dtype=jnp.float32)\n",
    "\n",
    "result = vector_add_op(\n",
    "    a, b,\n",
    "    outs=[jax.ShapeDtypeStruct((n,), dtype=jnp.float32)]\n",
    ")\n",
    "\n",
    "print(\"Input a:\", a)\n",
    "print(\"Input b:\", b)\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Sparse Matrix-Vector Multiplication\n",
    "\n",
    "Brain networks are typically sparse. Let's implement a sparse matrix-vector multiplication operator using CSR (Compressed Sparse Row) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:41:52.185808Z",
     "start_time": "2025-10-29T11:41:52.181631Z"
    }
   },
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def csr_matvec(\n",
    "    values: ti.types.ndarray(ndim=1),\n",
    "    indices: ti.types.ndarray(ndim=1),\n",
    "    indptr: ti.types.ndarray(ndim=1),\n",
    "    vector: ti.types.ndarray(ndim=1),\n",
    "    out: ti.types.ndarray(ndim=1)\n",
    "):\n",
    "    # Iterate over each row\n",
    "    for row in range(indptr.shape[0] - 1):\n",
    "        row_sum = 0.0\n",
    "        # Iterate over non-zero elements in the row\n",
    "        for j in range(indptr[row], indptr[row + 1]):\n",
    "            col = indices[j]\n",
    "            row_sum += values[j] * vector[col]\n",
    "        out[row] = row_sum\n",
    "\n",
    "# Register the operator\n",
    "csr_matvec_op = bti.XLACustomOp(\n",
    "    cpu_kernel=csr_matvec,\n",
    "    gpu_kernel=csr_matvec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:41:55.760741Z",
     "start_time": "2025-10-29T11:41:55.501971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom operator result: [1.8271513 2.4389558 1.7941285 2.318161  1.7279923]\n",
      "Expected result: [1.82715139 2.43895573 1.79412849 2.31816102 1.72799216]\n",
      "Maximum difference: 3.8372544519660323e-07\n"
     ]
    }
   ],
   "source": [
    "# Create a sparse matrix\n",
    "n_rows, n_cols = 100, 100\n",
    "density = 0.1\n",
    "dense_matrix = (np.random.rand(n_rows, n_cols) < density).astype(float)\n",
    "dense_matrix *= np.random.rand(n_rows, n_cols)\n",
    "\n",
    "# Convert to CSR format\n",
    "sparse_matrix = csr_matrix(dense_matrix)\n",
    "\n",
    "# Create input vector\n",
    "input_vector = np.random.rand(n_cols).astype(np.float32)\n",
    "\n",
    "# Run the custom operator\n",
    "result = csr_matvec_op(\n",
    "    jnp.array(sparse_matrix.data, dtype=jnp.float32),\n",
    "    jnp.array(sparse_matrix.indices, dtype=jnp.int32),\n",
    "    jnp.array(sparse_matrix.indptr, dtype=jnp.int32),\n",
    "    jnp.array(input_vector, dtype=jnp.float32),\n",
    "    outs=[jax.ShapeDtypeStruct((n_rows,), dtype=jnp.float32)]\n",
    ")\n",
    "\n",
    "# Verify the result\n",
    "expected = sparse_matrix @ input_vector\n",
    "print(\"Custom operator result:\", result[0][:5])\n",
    "print(\"Expected result:\", expected[:5])\n",
    "print(\"Maximum difference:\", np.max(np.abs(np.array(result[0]) - expected)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Event-Driven Computation\n",
    "\n",
    "Brain dynamics are often event-driven. Let's implement an event-driven synaptic transmission operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:30:43.094991Z",
     "start_time": "2025-10-29T09:30:43.090598Z"
    }
   },
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def event_csr_matvec(\n",
    "    values: ti.types.ndarray(ndim=1),\n",
    "    indices: ti.types.ndarray(ndim=1),\n",
    "    indptr: ti.types.ndarray(ndim=1),\n",
    "    events: ti.types.ndarray(ndim=1),  # Boolean array indicating which neurons fired\n",
    "    out: ti.types.ndarray(ndim=1)\n",
    "):\n",
    "    # Only process rows where events occurred\n",
    "    ti.loop_config(serialize=True)\n",
    "    for row in range(indptr.shape[0] - 1):\n",
    "        if events[row]:  # Only process if neuron fired\n",
    "            for j in range(indptr[row], indptr[row + 1]):\n",
    "                col = indices[j]\n",
    "                out[col] += values[j]\n",
    "\n",
    "# Register the operator\n",
    "event_csr_op = bti.XLACustomOp(\n",
    "    cpu_kernel=event_csr_matvec,\n",
    "    gpu_kernel=event_csr_matvec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:30:45.498739Z",
     "start_time": "2025-10-29T09:30:45.261150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons that fired: 98\n",
      "Synaptic input statistics:\n",
      "  Mean: 2.4380\n",
      "  Max: 5.0876\n",
      "  Non-zero entries: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create test data\n",
    "n_neurons = 1000\n",
    "density = 0.1\n",
    "\n",
    "# Create sparse connectivity matrix\n",
    "connectivity = (np.random.rand(n_neurons, n_neurons) < density).astype(float)\n",
    "connectivity *= np.random.rand(n_neurons, n_neurons) * 0.5  # Synaptic weights\n",
    "sparse_conn = csr_matrix(connectivity)\n",
    "\n",
    "# Generate random spike events (10% of neurons fire)\n",
    "events = np.random.rand(n_neurons) < 0.1\n",
    "\n",
    "# Run the event-driven operator\n",
    "result = event_csr_op(\n",
    "    jnp.array(sparse_conn.data, dtype=jnp.float32),\n",
    "    jnp.array(sparse_conn.indices, dtype=jnp.int32),\n",
    "    jnp.array(sparse_conn.indptr, dtype=jnp.int32),\n",
    "    jnp.array(events, dtype=jnp.bool_),\n",
    "    outs=[jax.ShapeDtypeStruct((n_neurons,), dtype=jnp.float32)]\n",
    ")\n",
    "\n",
    "print(f\"Number of neurons that fired: {events.sum()}\")\n",
    "print(f\"Synaptic input statistics:\")\n",
    "print(f\"  Mean: {np.mean(result[0]):.4f}\")\n",
    "print(f\"  Max: {np.max(result[0]):.4f}\")\n",
    "print(f\"  Non-zero entries: {np.sum(np.array(result[0]) > 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using Built-in Operators\n",
    "\n",
    "`braintaichi` provides many pre-implemented operators for common brain dynamics operations. Let's explore some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:30:48.088038Z",
     "start_time": "2025-10-29T09:30:48.085357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available modules in braintaichi:\n",
      "['XLACustomOp', 'coo_to_csr', 'coomv', 'cpu_ops', 'csr_to_coo', 'csr_to_dense', 'csrmm', 'csrmv', 'defjvp', 'event_csrmm', 'event_csrmv', 'get_homo_weight_matrix', 'get_normal_weight_matrix', 'get_uniform_weight_matrix', 'jitc_event_mv_prob_homo', 'jitc_event_mv_prob_normal', 'jitc_event_mv_prob_uniform', 'jitc_mv_prob_homo', 'jitc_mv_prob_normal', 'jitc_mv_prob_uniform', 'rand', 'register_general_batching']\n"
     ]
    }
   ],
   "source": [
    "# Check available operators in braintaichi\n",
    "print(\"Available modules in braintaichi:\")\n",
    "print([attr for attr in dir(bti) if not attr.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "Here are some key tips for optimizing your custom operators:\n",
    "\n",
    "1. **Parallelize outer loops**: Taichi automatically parallelizes the outermost for-loops\n",
    "2. **Use `ti.loop_config(serialize=True)`**: When you need sequential execution or want to use break statements\n",
    "3. **Choose appropriate data types**: Use `ti.f32` for single precision, `ti.f64` for double precision\n",
    "4. **Avoid Python objects inside kernels**: Use Taichi native types only\n",
    "5. **Batch operations**: Process multiple operations together to reduce overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with JAX\n",
    "\n",
    "One of the powerful features of `braintaichi` is seamless integration with JAX, enabling automatic differentiation and JIT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:30:53.618218Z",
     "start_time": "2025-10-29T09:30:53.453791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network output: [4.365637  1.9171182 1.9304688 2.2530348 2.110351 ]\n"
     ]
    }
   ],
   "source": [
    "# Example: Using braintaichi operator in a JAX JIT-compiled function\n",
    "@jax.jit\n",
    "def neural_network_step(weights_data, weights_indices, weights_indptr, inputs):\n",
    "    \"\"\"Simulate one step of a spiking neural network\"\"\"\n",
    "    n = inputs.shape[0]\n",
    "    # Apply synaptic weights\n",
    "    synaptic_input = csr_matvec_op(\n",
    "        weights_data,\n",
    "        weights_indices,\n",
    "        weights_indptr,\n",
    "        inputs,\n",
    "        outs=[jax.ShapeDtypeStruct((n,), dtype=jnp.float32)]\n",
    "    )\n",
    "    return synaptic_input\n",
    "\n",
    "# Test the JIT-compiled function\n",
    "n = 100\n",
    "sparse_mat = csr_matrix((np.random.rand(n, n) < 0.1).astype(float) * np.random.rand(n, n))\n",
    "inputs = jnp.array(np.random.rand(n), dtype=jnp.float32)\n",
    "\n",
    "result = neural_network_step(\n",
    "    jnp.array(sparse_mat.data, dtype=jnp.float32),\n",
    "    jnp.array(sparse_mat.indices, dtype=jnp.int32),\n",
    "    jnp.array(sparse_mat.indptr, dtype=jnp.int32),\n",
    "    inputs\n",
    ")\n",
    "\n",
    "print(\"Neural network output:\", result[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've learned the basics, you can:\n",
    "\n",
    "1. Read the **braintaichi_intro.ipynb** for detailed kernel registration interfaces\n",
    "2. Explore the **complete_example.ipynb** for more complex use cases\n",
    "3. Check out the **advanced_optimization.ipynb** for performance optimization techniques\n",
    "4. Visit the [API Documentation](https://braintaichi.readthedocs.io/) for detailed reference\n",
    "\n",
    "For more examples, check the source code:\n",
    "- [Event operators](https://github.com/chaoming0625/braintaichi/tree/main/braintaichi/_eventop)\n",
    "- [Sparse operators](https://github.com/chaoming0625/braintaichi/tree/main/braintaichi/_sparseop)\n",
    "- [JIT connection operators](https://github.com/chaoming0625/braintaichi/tree/main/braintaichi/_jitconnop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braintaichi_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
